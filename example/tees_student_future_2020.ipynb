{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tees_student_future_2020.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvb03k3cdZy9",
        "colab_type": "text"
      },
      "source": [
        "# Colab Notebook for Teesside University Student Future Workshop #\n",
        "\n",
        "This Notebook is designed for Teesside University Student Future 2020 workshop event.\n",
        "\n",
        "It covers the possible topics for AI / ML deverlopers in industry. \n",
        "\n",
        "The following dataset and model focus the Natural Language Process application.\n",
        "\n",
        "Authors: Teng Fu, Jing Tang, Annalisa Occhipinti\n",
        "\n",
        "Emails: teng.fu@teleware.com, J.Tang@tees.ac.uk, A.Occhipinti@tees.ac.uk\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4mWATtidZrc",
        "colab_type": "text"
      },
      "source": [
        "## Tasks ##\n",
        "\n",
        "Basic Tasks includes:\n",
        "\n",
        "- Prepare development environment.\n",
        "\n",
        "- Data pre-process.\n",
        "\n",
        "- Use pre-trained model.\n",
        "\n",
        "- Train your customised text classification model.\n",
        "\n",
        "- Deploy the model as a REST API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBktkodldYzi",
        "colab_type": "text"
      },
      "source": [
        "## Prepare development environment ##\n",
        "\n",
        "Environment consists two layers:\n",
        "\n",
        "- OS level.\n",
        "\n",
        "- Python level.\n",
        "\n",
        "For system level tools, use ```apt-get install packageX``` for package installation.\n",
        "\n",
        "For Python level tools, use ```pip install packageX ``` for package installation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmvtZPThwnAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pdpipe\n",
        "!pip install transformers\n",
        "!pip install hug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ5TnBFEwzbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import Python packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pdpipe as pdp\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn import svm\n",
        "# from sklearn.externals import joblib\n",
        "\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjSz3SnK0lqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load jupyter notebook extension\n",
        "%load_ext google.colab.data_table\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlbhxW8AdY-v",
        "colab_type": "text"
      },
      "source": [
        "## Data Pre-process ##\n",
        "\n",
        "Data pre-process is a neccessary step before model training. It basically follows the __ETL (Extract, Transform, Load)__ procedure, aims to support model training with high quality, clean data for better model performance.\n",
        "\n",
        "In this workshop, [Stanford Sentiment Treebank](https://nlp.stanford.edu/sentiment/index.html) dataset is utilised for model __training__.\n",
        "\n",
        "We will manually create our __test__ dataset through __ETL__ process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L17rgGYBdZB1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Extract ###\n",
        "\n",
        "Fetch the data from sources Github\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYUek7zbh_3e",
        "colab_type": "text"
      },
      "source": [
        "#### Fetch training data ####"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk28jsMltRs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sst2_training_data_tsv_file_address = 'https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv'\n",
        "\n",
        "train_column_names = [\"sentence\", \"label\"]\n",
        "df_train = pd.read_csv(sst2_training_data_tsv_file_address, delimiter='\\t', names=train_column_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp5vtjiqiGj1",
        "colab_type": "text"
      },
      "source": [
        "#### Fetch raw test data ####"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXEfalwZiIwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_test_csv_file_address = \"https://raw.githubusercontent.com/gitathrun/Teesside_University_Student_Future_2020_Workshop/master/raw_test_dataset.csv\"\n",
        "\n",
        "df_test_raw = pd.read_csv(raw_test_csv_file_address)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4uManxErHC2",
        "colab_type": "text"
      },
      "source": [
        "### Observation ### \n",
        "\n",
        "- Know your problem.\n",
        "\n",
        "- Observe raw data.\n",
        "\n",
        "- How to improve its quality?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD7aw8Sm-GfN",
        "colab_type": "text"
      },
      "source": [
        "#### Observe Training Data ####"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq7Len5Y-PFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATxuLNDA-Hnl",
        "colab_type": "text"
      },
      "source": [
        "#### Observe Raw Test Data ####"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Hl4gxE9_dQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test_raw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cn3ANFvdZEp",
        "colab_type": "text"
      },
      "source": [
        "### Transform ###\n",
        "Anonymization, Clean, Regularization, Labeling process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo_cVCv6tXqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Anonymization\n",
        "pipeline_drop_commenter_id = pdp.ColDrop(\"commenter_id\")\n",
        "anonym_df = pipeline_drop_commenter_id(df_test_raw)\n",
        "anonym_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ivZaM3iwB_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean Regularization\n",
        "# Use Python Regular Expression\n",
        "import re\n",
        "def remove_charactors(text):\n",
        "    regex = r\"(<|>|&|\\*)\"\n",
        "    subst = \"\"\n",
        "    clean_text = re.sub(regex, subst, text, 0)\n",
        "    return clean_text\n",
        "\n",
        "pipeline_clean_text = pdp.ApplyByCols('sentence', remove_charactors, result_columns='sentence')\n",
        "clean_text_df = pipeline_clean_text(anonym_df)\n",
        "clean_text_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBrftbGNrzEi",
        "colab_type": "text"
      },
      "source": [
        "### ETL pipeline ###\n",
        "\n",
        "Pipeline is a list of functions & operations orgernised in order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCN0098Oog7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# assemble the data preprocess pipeline\n",
        "pipeline_preprocess = pdp.PdPipeline([\n",
        "    pipeline_drop_commenter_id,\n",
        "    pipeline_clean_text\n",
        "])\n",
        "\n",
        "pipeline_preprocess"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO4hXtmhpEnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_pipe_test = pipeline_preprocess.apply(df_test_raw)\n",
        "df_pipe_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFtIb8ZdwB3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# labeling\n",
        "# manual labeling\n",
        "# or auto labeling again certain rules"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HWEXTfOl5WU",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Manual label the sentences\n",
        "#@markdown Select __0 (negative)__ or __1 (positive)__ in the Form as the sentiment label.\n",
        "\n",
        "#@markdown label_X means label for sentence at index X\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "label_0 = \"1\"  #@param [0, 1]\n",
        "label_1 = \"1\"  #@param [0, 1]\n",
        "label_2 = \"0\"  #@param [0, 1]\n",
        "label_3 = \"1\"  #@param [0, 1]\n",
        "label_4 = \"0\"  #@param [0, 1]\n",
        "label_5 = \"1\"  #@param [0, 1]\n",
        "label_6 = \"0\"  #@param [0, 1]\n",
        "label_7 = \"0\"  #@param [0, 1]\n",
        "label_8 = \"1\"  #@param [0, 1]\n",
        "label_9 = \"1\"  #@param [0, 1]\n",
        "label_10 = \"1\"  #@param [0, 1]\n",
        "label_11 = \"1\"  #@param [0, 1]\n",
        "label_12 = \"0\"  #@param [0, 1]\n",
        "label_13 = \"0\"  #@param [0, 1]\n",
        "label_14 = \"0\"  #@param [0, 1]\n",
        "\n",
        "#@markdown ---\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MiwUfkQ3J5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# collect labels and concat with processed dataframe\n",
        "str_label_list = [  label_0,\n",
        "                    label_1,\n",
        "                    label_2,\n",
        "                    label_3,\n",
        "                    label_4,\n",
        "                    label_5,\n",
        "                    label_6,\n",
        "                    label_7,\n",
        "                    label_8,\n",
        "                    label_9,\n",
        "                    label_10,\n",
        "                    label_11,\n",
        "                    label_12,\n",
        "                    label_13,\n",
        "                    label_14]\n",
        "\n",
        "# need to convert string type label into integer type\n",
        "int_label_list = [int(label) for label in str_label_list]\n",
        "\n",
        "label_dict = {\"label\": int_label_list}\n",
        "\n",
        "df_test_label = pd.DataFrame(label_dict)\n",
        "df_test_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMcr9sXkATcD",
        "colab_type": "text"
      },
      "source": [
        "#### Merge labels with cleaned data ####"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64zswZTQAX3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test_processed = pd.concat([df_pipe_test, df_test_label], axis=1)\n",
        "df_test_processed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlvcatHPpzGE",
        "colab_type": "text"
      },
      "source": [
        "### Load ###\n",
        "\n",
        "Save the transformed data to certain places: cloud storage, database, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRYlpJPptl1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test_processed.to_csv(\"processed_test_dataset.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFUTEfLkpzAR",
        "colab_type": "text"
      },
      "source": [
        "## Transfer Learning with pre-trained model ##\n",
        "\n",
        "We re going to use two machine learning frameworks:\n",
        "- PyTorch: we will use __BERT__ as the text encoder model based on PyTorch.\n",
        "\n",
        "- Keras: We will build a __Multi-Layer Perceptron__ as the upstream classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzS9mtuveXD_",
        "colab_type": "text"
      },
      "source": [
        "### Loading the Pre-trained BERT model ###\n",
        "\n",
        "__B__idirectional __E__ncoder __R__epresentations from __T__ransformers is a technique for NLP pre-training developed by Google. [__BERT__](https://github.com/google-research/bert) was created and published in 2018 by Jacob Devlin and his colleagues from Google. \n",
        "\n",
        "Here we use PyTorch version BERT developed by [huggingface](https://github.com/huggingface/transformers). The parameters are identical with Google's Tensorflow version, but this is is developed with PyTorch framework."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8a72feMtJbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use PyTorch Hub\n",
        "\n",
        "# fetch tokenizer\n",
        "# Download vocabulary from S3 and cache.\n",
        "loaded_tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased')   \n",
        "\n",
        "# fetch model\n",
        "loaded_model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-uncased') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb1DNl2txgx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# text --> tokens\n",
        "def text_tokenization(text, tokenizer_model=loaded_tokenizer):\n",
        "    tokenized_ids = tokenizer_model.encode(text, add_special_tokens=True)\n",
        "    return tokenized_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIbTyqs7x4vF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokens --> encode vector\n",
        "def tokens_encoding(tokenized_ids, bert_model=loaded_model):\n",
        "    input_ids = torch.tensor([tokenized_ids])\n",
        "    with torch.no_grad():\n",
        "        # only the pooled vector at position 0: [CLS]\n",
        "        encoding = bert_model(input_ids)[0][:,0,:].numpy()\n",
        "    encoding = encoding.reshape([768])\n",
        "    return encoding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aBnuC2izXep",
        "colab_type": "text"
      },
      "source": [
        "### BERT Encoding Pipeline ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKQQ4z6fzNMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline_tokenization = pdp.ApplyByCols('sentence', text_tokenization, result_columns='tokenized_ids', drop=False)\n",
        "pipeline_encoding = pdp.ApplyByCols('tokenized_ids', tokens_encoding, result_columns='bert_encoding', drop=False)\n",
        "\n",
        "# assemble the bert encoding pipeline\n",
        "pipeline_bert_encoding = pdp.PdPipeline([\n",
        "    pipeline_tokenization,\n",
        "    pipeline_encoding\n",
        "])\n",
        "\n",
        "pipeline_bert_encoding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E01eBbhV0vM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BERT encoding training data\n",
        "df_train_batch = df_train[:1000]\n",
        "%time df_training_bert_encoding = pipeline_bert_encoding(df_train_batch)\n",
        "# df_training_bert_encoding.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF4aUqjKJ2D9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train_batch.label.values.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulLsiQ1M8whs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BERT encoding test data\n",
        "%time df_test_bert_encoding = pipeline_bert_encoding(df_test_processed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ2-N8cF9odp",
        "colab_type": "text"
      },
      "source": [
        "#### Save the vectors in numpy format ####\n",
        "\n",
        "Do Not Save the numpy array in .csv format, for it will consider the vector numeric as string, and use ... to replace the long string.\n",
        "\n",
        "Use numpy's __.npy__ format. This is a standard format that is supported by most Deep Learning frameworks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYFFfLxfEZ_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make sure the values in dataframe \n",
        "# can be properly converted into correct shape numpy array\n",
        "def reshape_dataframe_array(values_array):\n",
        "    values_list = values_array.tolist()\n",
        "    np_array = np.array(values_list)\n",
        "    return np_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi-e0J0f9uDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save training dataset batch\n",
        "np_training_bert_encoding_batch = reshape_dataframe_array(df_training_bert_encoding.bert_encoding.values)\n",
        "np.save(\"np_training_bert_encoding_batch.npy\", np_training_bert_encoding_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-4g04Ci_Yi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save test dataset\n",
        "np_test_bert_encoding = reshape_dataframe_array(df_test_bert_encoding.bert_encoding.values)\n",
        "np_test_bert_encoding.shape\n",
        "np.save(\"np_test_bert_encoding.npy\", np_test_bert_encoding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueRPZOoXyFWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for text encoding\n",
        "def text_to_vector(text, tokenizer_model=loaded_tokenizer, bert_model=loaded_model):\n",
        "    input_ids = torch.tensor([tokenizer_model.encode(text, add_special_tokens=True)])\n",
        "    with torch.no_grad():\n",
        "        last_hidden_states = bert_model(input_ids)[0]\n",
        "    text_encoding = last_hidden_states.numpy()[0,0,:]\n",
        "    return text_encoding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "447RL14ipy9e",
        "colab_type": "text"
      },
      "source": [
        "## Train your customised text classification model ##\n",
        "\n",
        "Train a simple two hidden-layer MLP classifier wit Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e861yi2AbkBW",
        "colab_type": "text"
      },
      "source": [
        "#### Construct the MLP Classifier and its Hyper-parameters ####"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBqt9fSLG4Z4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct neural network in Sequential manner\n",
        "clf = Sequential()\n",
        "clf.add(Dense(256, input_dim=768))\n",
        "clf.add(Activation('relu'))\n",
        "clf.add(Dropout(0.3))\n",
        "clf.add(Dense(64, activation='relu'))\n",
        "clf.add(Dropout(0.3))\n",
        "clf.add(Dense(2, activation='softmax'))\n",
        "\n",
        "adam = Adam()\n",
        "\n",
        "clf.compile(loss='binary_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li3Cpt4jJehx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the classifier\n",
        "x_train = np_training_bert_encoding_batch\n",
        "y_train = df_train_batch.label.values.reshape((1000, 1))\n",
        "one_hot_labels_train = keras.utils.to_categorical(y_train, num_classes=2)\n",
        "\n",
        "train_history = clf.fit(x_train,\n",
        "                        one_hot_labels_train,\n",
        "                        validation_split=0.10,\n",
        "                        epochs=50,\n",
        "                        batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9HkeAwdM-2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.utils.plot_model(clf, to_file=\"clf.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nBIGFDBITF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(train_history.history['acc'])\n",
        "plt.plot(train_history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Dev'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BRE8pJhIUZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot training & validation loss values\n",
        "plt.plot(train_history.history['loss'])\n",
        "plt.plot(train_history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Dev'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTJUeof51Cx-",
        "colab_type": "text"
      },
      "source": [
        "Is the trained classifier good?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeG9EWsHMUPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = np_test_bert_encoding\n",
        "y_test = df_test_bert_encoding.label.values.reshape((15,1))\n",
        "one_hot_labels_test = keras.utils.to_categorical(y_test, num_classes=2)\n",
        "\n",
        "score = clf.evaluate(x_test, one_hot_labels_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTKdp0OOMqf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check the evaluation result\n",
        "print(\"Loss evaluation on Test data: {}\".format(score[0]))\n",
        "print(\"Accuracy evaluation on Test data: {}\".format(score[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69H8AHq63FlU",
        "colab_type": "text"
      },
      "source": [
        "### Check Prediction and Evaluate trained model ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfFDHP-g1GrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check the prediction\n",
        "y_pred = clf.predict(x_test)\n",
        "print(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_tB2rCQ3byn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU9M2PGb3kJR",
        "colab_type": "text"
      },
      "source": [
        "### Interprete the model with confustion matrix and other metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZHsCwhM3zyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# convert it with argmax\n",
        "y_pred_1d = np.argmax(y_pred, axis=1)\n",
        "y_pred_1d\n",
        "\n",
        "# make sure the array shape is 1D\n",
        "y_true = y_test.reshape((-1))\n",
        "\n",
        "# get confustion matrix\n",
        "cm = confusion_matrix(y_true, y_pred_1d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87yZcQIO4B1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot non-normalized confusion matrix\n",
        "target_names = ['positive', 'negative']\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=target_names)\n",
        "disp.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asxTCX131mr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classification detail\n",
        "print(classification_report(y_true, y_pred_1d, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZWbAlj-MOJF",
        "colab_type": "text"
      },
      "source": [
        "### Save the trained Keras classifier model ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gIIEL1t0wFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save trained model\n",
        "clf.save(\"trained_sentiment_classifier.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqazo3XP00N0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load from local storage\n",
        "# loaded_clf = load_model(\"/content/trained_sentiment_classifier.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmsv6qz-py6c",
        "colab_type": "text"
      },
      "source": [
        "## Deploy the model as a REST API ##\n",
        "\n",
        "Since the encoder and upstream classifier is trained, developer can deploy them behind a REST API for users to access.\n",
        "\n",
        "[hug](https://www.hug.rest/) package is used for REST API deployment within Jupyter Notebook environment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOy4rZFXxSjb",
        "colab_type": "text"
      },
      "source": [
        "### Setup API Server and run ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kklUnwo4xVka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile sentiment_api.py\n",
        "import hug\n",
        "import torch\n",
        "from keras.models import load_model\n",
        "\n",
        "# intialisation\n",
        "# fetch tokenizer\n",
        "# Download vocabulary from S3 and cache.\n",
        "loaded_tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased')   \n",
        "\n",
        "# fetch bert model\n",
        "loaded_bert_model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-uncased') \n",
        "\n",
        "# fetch keras model\n",
        "loaded_keras_model = load_model(\"trained_sentiment_classifier.h5\")\n",
        "\n",
        "# text --> tokens\n",
        "def text_tokenization(text, tokenizer_model=loaded_tokenizer):\n",
        "    tokenized_ids = tokenizer_model.encode(text, add_special_tokens=True)\n",
        "    return tokenized_ids\n",
        "\n",
        "    # tokens --> encode vector\n",
        "def tokens_encoding(tokenized_ids, bert_model=loaded_bert_model):\n",
        "    input_ids = torch.tensor([tokenized_ids])\n",
        "    with torch.no_grad():\n",
        "        # only the pooled vector at position 0: [CLS]\n",
        "        encoding = bert_model(input_ids)[0][:,0,:].numpy()\n",
        "    encoding = encoding.reshape((1, 768))\n",
        "    return encoding\n",
        "\n",
        "def predict_sentiment(encoding, keras_model=loaded_keras_model):\n",
        "    sentiment_prob = keras_model.predict(encoding)\n",
        "    return sentiment_prob\n",
        "\n",
        "@hug.post(\"/sentiment\")\n",
        "def sentiment(text):\n",
        "    token_ids = text_tokenization(text)\n",
        "    encoding = tokens_encoding(token_ids)\n",
        "    sentiment_prob = predict_sentiment(encoding)\n",
        "    return {'sentiment': sentiment_prob}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz2KlZ7azjhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run API server but detach it from terminal\n",
        "!nohup hug -f sentiment_api.py &"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMRcbZybz9qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check nohup log\n",
        "!cat nohup.out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgzVVA4UzyFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check hug is running\n",
        "!ps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrHKnALYz1pA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# stop hug server with its PID\n",
        "!kill 1467 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI7i4xVUxV1U",
        "colab_type": "text"
      },
      "source": [
        "### Make a client request ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEEfKT7nxY91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "# headers = {\"content-type\": \"application/json\"}\n",
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "# ready the body\n",
        "# change the text in a form\n",
        "input_text = 'That is a bad movie!'  #@param {type: \"string\"}\n",
        "data = {\"text\": input_text}\n",
        "\n",
        "# POST request to server\n",
        "json_response = requests.post('http://localhost:8000/sentiment', json=data, headers=headers)\n",
        "\n",
        "# parse the recieved json \n",
        "print(json_response)\n",
        "print(json_response.text)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}